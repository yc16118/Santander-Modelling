{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np, pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.optimize import minimize\n",
    "import scipy.stats as stats\n",
    "from matplotlib.ticker import FuncFormatter\n",
    "import scipy.optimize as op\n",
    "import os\n",
    "from nltk import flatten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the same function in the mutually exciting process model of arrival and departure at station i, to filter the event times in process j that occurred before event time T in station i."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prev_event(times, T):\n",
    "    \"\"\"\n",
    "    Return the event times in process j that happens before event time T in process i.\n",
    "    : param times: an n-dimensional array, the full event times in process j\n",
    "    : param T: a number, one event time in process i\n",
    "    \n",
    "    : return k: a number, the index of the last event time in process j happened before T in process i\n",
    "    \"\"\"\n",
    "    \n",
    "    return np.searchsorted(times, T, side='right')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And again, similar to previous model, we use a dictionary to store all the filtered event times in each process j = 1, ..., m. We take T as the last event time observed in process i for our chosen piece of data. We label i as j=1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_times(location_codes, times, i):\n",
    "    \"\"\"\n",
    "    Return the departure and arrival times observed at station j = 1, ..., m, before the last event time\n",
    "    observed in departure process at station i.\n",
    "    \n",
    "    : param location_codes: a list of length M, the location codes of all M stations, with i as the first.\n",
    "    : param times: a dictionary, storing the departure and arrival times from station j = 1, ..., M as values, \\\n",
    "    and the location codes of corresponding stations as keys.\n",
    "    : param i: the index of the station being studied\n",
    "    \n",
    "    : return times: a dictionary, storing all relevant event times\n",
    "    \"\"\"\n",
    "    \n",
    "    ii = get_station_index(location_codes, i)\n",
    "    arr_times = times['arrival']\n",
    "    dep_times = times['departure']\n",
    "    T = dep_times[i][-1]\n",
    "    ind_list = []\n",
    "    ind1_list = []\n",
    "    new_times = {}\n",
    "    new_deptimes={}\n",
    "    new_arrtimes={}\n",
    "    \n",
    "    for j in range(len(location_codes)):\n",
    "        ind = prev_event(dep_times[location_codes[j]], T)\n",
    "        if j != ii and ind != 0:\n",
    "            new_deptimes[location_codes[j]] = dep_times[location_codes[j]][:ind]\n",
    "        \n",
    "        if ind == 0:\n",
    "            ind_list.append(location_codes[j])\n",
    "        \n",
    "        if j == ii:\n",
    "            new_deptimes[location_codes[j]] = dep_times[location_codes[j]]\n",
    "        \n",
    "        ind1 = prev_event(arr_times[location_codes[j]], T)\n",
    "        if ind1 != 0:\n",
    "            new_arrtimes[location_codes[j]] = arr_times[location_codes[j]][:ind1]\n",
    "        \n",
    "        if ind1 == 0:\n",
    "            ind1_list.append(location_codes[j])\n",
    "     \n",
    "    new_times['arrival'] = new_arrtimes\n",
    "    new_times['departure'] = new_deptimes\n",
    "    \n",
    "    return new_times, ind_list, ind1_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For log likelihood, we still follow the previous model, to get function for $A_{ii}(1)$, ..., $A_{ii}(h)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def A_ii(theta, times_i):\n",
    "    \"\"\"\n",
    "    Finds the array of function A_i, from 1st event to hth event in process i\n",
    "    \n",
    "    : param theta: a real number\n",
    "    : param times_i, a 1-D array, the event times observed in process i\n",
    "    \n",
    "    : return A: a 1D array\n",
    "    \"\"\"\n",
    "   \n",
    "    A = np.zeros(len(times_i))\n",
    "    \n",
    "    for h in range(1, len(times_i)):\n",
    "        A[h] = np.exp(-theta*(times_i[h] - times_i[h-1]))*(1+A[h-1])\n",
    "        \n",
    "    return A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.13533528, 0.15365092])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A_ii(2, np.array([1, 2, 3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And for $A_{ij}(1)$, ..., $A_{ij}(h)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def A_ij(theta, times_i, times_j):\n",
    "    \"\"\"\n",
    "    Finds the array of function A_ij, for all event times in process j = 1, ..., M\n",
    "    \n",
    "    : param theta: a real number\n",
    "    : param times_i, a 1-D array, the event times observed in process i\n",
    "    : param times_j, a 1-D array, the event times observed in process j\n",
    "    \n",
    "    : return B: a 1-D array\n",
    "    \"\"\"\n",
    "    \n",
    "    B = np.zeros(len(times_i))\n",
    "    ind = prev_event(times_j, times_i[0])\n",
    "    \n",
    "    B[0] = np.sum(np.exp(- theta * (times_i[0] - times_j[:ind])))\n",
    "    \n",
    "    for h in range(1, len(times_i)):\n",
    "        B[h] = np.exp(-theta * (times_i[h] - times_i[h-1])) * B[h-1] \n",
    "        new_ind = prev_event(times_j, times_i[h])\n",
    "        if ind != new_ind:\n",
    "            B[h] += np.sum(np.exp(- theta * (times_i[h] - times_j[ind:new_ind])))\n",
    "            ind = new_ind#prev_event(times_j, times_i[h])\n",
    "        \n",
    "    return B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also write a function to find the excitation terms of each station"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "def excitation_j(theta, t, times_j):\n",
    "    \"\"\"\n",
    "    Finds the array of function excitation_j, for all event times in process j = 1, ..., M\n",
    "    \n",
    "    : param theta: a real number, thetaj\n",
    "    : param times_i, a 1-D array, the event times observed in process i\n",
    "    : param times_j, a 1-D array, the event times observed in process j\n",
    "    \n",
    "    : return Ej: a 1-D array\n",
    "    \"\"\"\n",
    "    #Ej = 0\n",
    "    ind = prev_event(times_j, t)\n",
    "    Ej = np.zeros(ind)\n",
    "    if ind != 0:\n",
    "            Ej = np.exp(-theta*(t - times_j[0:ind])) - 1\n",
    "    #for i in range(ind):\n",
    "        #Ej += np.exp(-theta*(t - times_j[i])) - 1\n",
    "    \n",
    "    return Ej"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And log likelihood is hence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seven_comp(t, location_codes, event_times, beta_dep, theta_dep, beta_arr, theta_arr, k_dep, k_arr, lambda_b, dist, i): \n",
    "    \n",
    "    arr_times = event_times[\"arrival\"]\n",
    "    dep_times = event_times[\"departure\"]\n",
    "    times_i = arr_times[i]\n",
    "    kappa_dep = kappa_fun(dist, k_dep)\n",
    "    kappa_arr = kappa_fun(dist, k_arr)\n",
    "    ratio_dep = kappa_dep*beta_dep/theta_dep\n",
    "    ratio_arr = kappa_arr*beta_arr/theta_arr\n",
    "    \n",
    "    ex_terms = 0\n",
    "    \n",
    "    for j in range(len(location_codes)):\n",
    "        times_dep = dep_times[location_codes[j]]\n",
    "        times_arr = arr_times[location_codes[j]]\n",
    "        ind_dep = prev_event(times_dep, t)\n",
    "        ind_arr = prev_event(times_arr, t)\n",
    "        \n",
    "        if ind_dep != 0:\n",
    "            ex_terms += ratio_dep[j] * np.sum(excitation_j(theta_dep, t, times_dep[0:ind_dep]))\n",
    "        if ind_arr != 0:\n",
    "            ex_terms += ratio_arr[j] * np.sum(excitation_j(theta_arr, t, times_arr[0:ind_arr]))\n",
    "    \n",
    "    res = lambda_b*t - ex_terms \n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seven_log_likelihood(location_codes, event_times, beta_dep, theta_dep, beta_arr, theta_arr, \n",
    "                        k_dep, k_arr, lambda_b, dist, i): \n",
    "    \"\"\"\n",
    "    Finds the log-likelihood of the mutually exciting process between stations\n",
    "    \n",
    "    : param location_codes: a list of length M, the location codes of all M stations with i as the first\n",
    "    : param event_times: a dictionary, the event times in all processes \\\n",
    "      that occurred before the last event in process i \n",
    "    : param beta: a real number\n",
    "    : param theta: a real number\n",
    "    : param k: a real number\n",
    "    : param dist: a 1-D array of length M, which stores the distances of each station\n",
    "    : param lambda_b: a real number, the baseline intensity of station i\n",
    "    : param i: the index of the station being studied\n",
    "    \n",
    "    : return A: a real number, the baseline intensity of station i\n",
    "    \"\"\"\n",
    "    ind = i#ind = get_station_index(location_codes, i)\n",
    "    arr_times = event_times[\"arrival\"]\n",
    "    dep_times = event_times[\"departure\"]\n",
    "    times_i = dep_times[i]\n",
    "    \n",
    "    kappa_dep = kappa_fun(dist, k_dep)\n",
    "    kappa_arr = kappa_fun(dist, k_arr)\n",
    "    ratio_dep = kappa_dep*beta_dep/theta_dep\n",
    "    ratio_arr = kappa_arr*beta_arr/theta_arr\n",
    "    T = times_i[-1]\n",
    "    \n",
    "    #Depature at station i\n",
    "    A = A_ii(theta_dep, times_i)\n",
    "    A = kappa_dep[ind]*beta_dep*A\n",
    "    ex_terms = ratio_dep[ind] * np.sum(excitation_j(theta_dep, T, times_i))\n",
    "    #Arrival at station i\n",
    "    A += kappa_arr[ind]*beta_arr*A_ij(theta_arr, times_i, arr_times[location_codes[ind]])\n",
    "    ex_terms += ratio_arr[ind] * np.sum(excitation_j(theta_arr, T, arr_times[location_codes[ind]]))\n",
    "    \n",
    "    for j in range(len(location_codes)):\n",
    "        if j != ind:\n",
    "            #Depature at station j\n",
    "            A += kappa_dep[j] * beta_dep * A_ij(theta_dep, times_i, dep_times[location_codes[j]])\n",
    "            ex_terms += ratio_dep[j] * np.sum(excitation_j(theta_dep, T, dep_times[location_codes[j]]))\n",
    "            #Arrival at station j\n",
    "            A += kappa_arr[j] * beta_arr * A_ij(theta_arr, times_i, arr_times[location_codes[j]])\n",
    "            ex_terms += ratio_arr[j] * np.sum(excitation_j(theta_arr, T, arr_times[location_codes[j]]))\n",
    "    \n",
    "    res = np.sum(np.log(lambda_b +A)) + ex_terms - lambda_b*T\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seven_log_likelihood2(location_codes, event_times, beta_dep, theta_dep, beta_arr, theta_arr, \n",
    "                        k_dep, k_arr, lambda_b, dist, i): \n",
    "    \"\"\"\n",
    "    Finds the log-likelihood of the mutually exciting process between stations\n",
    "    \n",
    "    : param location_codes: a list of length M, the location codes of all M stations with i as the first\n",
    "    : param event_times: a dictionary, the event times in all processes \\\n",
    "      that occurred before the last event in process i \n",
    "    : param beta: a real number\n",
    "    : param theta: a real number\n",
    "    : param k: a real number\n",
    "    : param dist: a 1-D array of length M, which stores the distances of each station\n",
    "    : param lambda_b: a real number, the baseline intensity of station i\n",
    "    : param i: the index of the station being studied\n",
    "    \n",
    "    : return A: a real number, the baseline intensity of station i\n",
    "    \"\"\"\n",
    "    ind = i#ind = get_station_index(location_codes, i)\n",
    "    arr_times = event_times[\"arrival\"]\n",
    "    dep_times = event_times[\"departure\"]\n",
    "    times_i = dep_times[i]\n",
    "    \n",
    "    kappa_dep = kappa_fun(dist, k_dep)\n",
    "    kappa_arr = kappa_fun(dist, k_arr)\n",
    "    ratio_dep = kappa_dep*beta_dep/theta_dep\n",
    "    ratio_arr = kappa_arr*beta_arr/theta_arr\n",
    "    T = times_i[-1]\n",
    "    ex_list = []\n",
    "    \n",
    "    #Depature at station i\n",
    "    A = A_ii(theta_dep, times_i)\n",
    "    A = kappa_dep[ind]*beta_dep*A\n",
    "    ex_terms = ratio_dep[ind] * np.sum(excitation_j(theta_dep, T, times_i))\n",
    "    ex_list.append(ratio_dep[ind] * np.sum(excitation_j(theta_dep, T, times_i)))\n",
    "    #Arrival at station i\n",
    "    A += kappa_arr[ind]*beta_arr*A_ij(theta_arr, times_i, arr_times[location_codes[ind]])\n",
    "    ex_terms += ratio_arr[ind] * np.sum(excitation_j(theta_arr, T, arr_times[location_codes[ind]]))\n",
    "    ex_list.append(ratio_arr[ind]*np.sum(excitation_j(theta_arr, T, arr_times[location_codes[ind]])))\n",
    "    \n",
    "    for j in range(len(location_codes)):\n",
    "        if j != ind:\n",
    "            #Depature at station j\n",
    "            A += kappa_dep[j] * beta_dep * A_ij(theta_dep, times_i, dep_times[location_codes[j]])\n",
    "            ex_terms += ratio_dep[j] * np.sum(excitation_j(theta_dep, T, dep_times[location_codes[j]]))\n",
    "            ex_list.append(ratio_dep[j] * np.sum(excitation_j(theta_dep, T, dep_times[location_codes[j]])))\n",
    "            #Arrival at station j\n",
    "            A += kappa_arr[j] * beta_arr * A_ij(theta_arr, times_i, arr_times[location_codes[j]])\n",
    "            ex_terms += ratio_arr[j] * np.sum(excitation_j(theta_arr, T, arr_times[location_codes[j]]))\n",
    "            ex_list.append(ratio_arr[j] * np.sum(excitation_j(theta_arr, T, arr_times[location_codes[j]])))\n",
    "    \n",
    "    res = np.sum(np.log(lambda_b +A)) + ex_terms - lambda_b*T\n",
    "    \n",
    "    return np.sum(np.log(lambda_b +A)), np.array(ex_list), lambda_b*T, - ex_terms + lambda_b*T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define the threshold function to select stations from a neighbourhood around the given station, at a threshold distance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "def thres_fun(dist, thres, loc_codes):\n",
    "    new_dist = dist.copy()\n",
    "    new_loc_codes = np.asarray(loc_codes).copy()\n",
    "    \n",
    "    index = [i for i in range(len(dist)) if dist[i] > thres]\n",
    "    new_dist[index] = -1\n",
    "    new_loc_codes[index] = -1\n",
    "    new_dist = [i for i in new_dist if i != -1]\n",
    "    new_loc_codes = [i for i in new_loc_codes if i != -1]\n",
    "    \n",
    "    return np.asarray(new_dist), new_loc_codes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the kappa function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kappa_fun(dist, k):\n",
    "    \n",
    "    return np.exp(-k * dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1, 2, 3]), [4, 5, 6])"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dist = np.array([1, 2, 3, 4, 5])\n",
    "k = 1\n",
    "thres = 3\n",
    "loc_codes = [4, 5, 6, 7, 8]\n",
    "thres_fun(dist, thres, loc_codes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.0 [0. 0. 0. 0.] 0.0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "beta_dep = 2.0\n",
    "beta_arr = 1.5\n",
    "theta_dep = 3.0\n",
    "theta_arr = 3.5\n",
    "dist = np.array([0, 0.5])\n",
    "k_dep = 0.5\n",
    "k_arr = 0.7\n",
    "kappa_dep = kappa_fun(dist, k_dep)\n",
    "kappa_arr = kappa_fun(dist, k_arr)\n",
    "lambda_b = 1.0\n",
    "location_codes = [0, 1]\n",
    "\n",
    "t0_dep = np.sort(np.random.uniform(0,75,size=3))\n",
    "t0_arr = np.sort(np.random.uniform(0,75,size=3))#np.array([1.0, 2.0, 3.0])\n",
    "t1_dep = np.sort(np.random.uniform(0,75,size=3))#np.array([43.0, 57.0, 62.0])\n",
    "t1_arr = np.sort(np.random.uniform(0,75,size=3))\n",
    "t_dep = {0: t0_dep, 1: t1_dep}\n",
    "t_arr = {0: t0_arr, 1: t1_arr}\n",
    "times = {'departure': t_dep, 'arrival': t_arr}\n",
    "\n",
    "tdict = process_times(location_codes, times, 0)[0]\n",
    "t0_dep0 = tdict['departure'][0]\n",
    "t0_arr0 = tdict['arrival'][0]\n",
    "t1_dep0 = tdict['departure'][1]\n",
    "t1_arr0 = tdict['arrival'][1]\n",
    "\n",
    "sum_1 = []\n",
    "for i in range(3):\n",
    "    log_term = lambda_b \n",
    "    if i == 1:\n",
    "        log_term += beta_dep*np.exp(-theta_dep*(t0_dep0[1] -t0_dep0[0]))\n",
    "    \n",
    "    if i == 2:\n",
    "        log_term += beta_dep*np.exp(-theta_dep*(t0_dep0[2] -t0_dep0[0])) + beta_dep*np.exp(-theta_dep*(t0_dep0[2] -t0_dep0[1]))\n",
    "    \n",
    "    ind = np.searchsorted(t0_arr0, t0_dep0[i], side='right')\n",
    "    for j in range(ind):\n",
    "        log_term += kappa_arr[0]*beta_arr*np.exp(-theta_arr*(t0_dep0[i] - t0_arr0[j]))\n",
    "        \n",
    "    ind = np.searchsorted(t1_dep0, t0_dep0[i], side='right')\n",
    "    for j in range(ind):\n",
    "        log_term += kappa_dep[1]*beta_dep*np.exp(-theta_dep*(t0_dep0[i] - t1_dep0[j]))\n",
    "    \n",
    "    ind = np.searchsorted(t1_arr0, t0_dep0[i], side='right')\n",
    "    for j in range(ind):\n",
    "        log_term += kappa_arr[1]*beta_arr*np.exp(-theta_arr*(t0_dep0[i] - t1_arr0[j]))\n",
    "    \n",
    "    sum_1.append(np.log(log_term))\n",
    "\n",
    "sum_2, sum_3, sum_4, sum_5 = 0.0, 0.0, 0.0, 0.0\n",
    "for i in range(3):\n",
    "    sum_2 += np.exp(-theta_dep*(t0_dep0[-1]-t0_dep0[i]))-1\n",
    "\n",
    "index = np.searchsorted(t0_arr0, t0_dep0[-1], side=\"Right\")\n",
    "sum3 = []\n",
    "for m in range(index):\n",
    "    sum_3 += np.exp(-theta_arr*(t0_dep0[-1]-t0_arr0[m]))-1\n",
    "    sum3.append(sum_3)\n",
    "    a = excitation_j(theta_arr, t0_dep0[-1], t0_arr0)\n",
    "\n",
    "index = np.searchsorted(t1_dep0, t0_dep0[-1], side=\"Right\")\n",
    "for m in range(index):\n",
    "    sum_4 += np.exp(-theta_dep*(t0_dep0[-1]-t1_dep0[m]))-1\n",
    "\n",
    "index = np.searchsorted(t1_arr0, t0_dep0[-1], side=\"Right\")\n",
    "for m in range(index):\n",
    "    sum_5 += np.exp(-theta_arr*(t0_dep0[-1]-t1_arr0[m]))-1\n",
    "    \n",
    "sum_Lambda = np.array([kappa_dep[0]*beta_dep/theta_dep * sum_2, kappa_arr[0]*beta_arr/theta_arr * sum_3,\n",
    "                       kappa_dep[1]*beta_dep/theta_dep * sum_4, kappa_arr[1]*beta_arr/theta_arr * sum_5])\n",
    "\n",
    "l = np.sum(sum_1) - lambda_b * t0_dep0[-1] + np.sum(sum_Lambda)\n",
    "u = seven_log_likelihood2(location_codes, times, beta_dep, theta_dep, beta_arr, theta_arr, k_dep, k_arr, lambda_b, dist, 0)\n",
    "#comp=diff_comp(t1[-1], location_codes, tdict, beta, theta, lambda_b, dist, k)\n",
    "print(np.abs(l - seven_log_likelihood(location_codes, times, beta_dep, theta_dep, beta_arr, theta_arr, k_dep, k_arr, lambda_b, dist, 0)));\n",
    "print(u[0] - np.sum(sum_1),\n",
    "u[1] - sum_Lambda, #np.sum(sum_Lambda),\n",
    "u[2] - lambda_b * t0_dep0[-1]);\n",
    "print(u[3] -seven_comp(t0_dep0[-1], location_codes, times, beta_dep, theta_dep, beta_arr, theta_arr, k_dep, k_arr, lambda_b, dist, 0))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
