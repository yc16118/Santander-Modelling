{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: haversine in /Users/jigglypuffy/Documents/anaconda3/lib/python3.11/site-packages (2.8.0)\r\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install haversine\n",
    "import haversine \n",
    "from sklearn.neighbors import DistanceMetric\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use(\"dark_background\")\n",
    "plt.rcParams['figure.dpi'] = 150\n",
    "from nltk import flatten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We read the santander_locations document, which contains the location information of bike stations across London."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "station_data = pd.read_csv(\"../Data/santander_locations.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Station.Id</th>\n",
       "      <th>StationName</th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>Easting</th>\n",
       "      <th>Northing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>River Street, Clerkenwell</td>\n",
       "      <td>-0.109971</td>\n",
       "      <td>51.529200</td>\n",
       "      <td>531202.520</td>\n",
       "      <td>182832.020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Phillimore Gardens, Kensington</td>\n",
       "      <td>-0.197574</td>\n",
       "      <td>51.499600</td>\n",
       "      <td>525207.070</td>\n",
       "      <td>179391.860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Christopher Street, Liverpool Street</td>\n",
       "      <td>-0.084606</td>\n",
       "      <td>51.521300</td>\n",
       "      <td>532984.810</td>\n",
       "      <td>182001.530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>St. Chad's Street, King's Cross</td>\n",
       "      <td>-0.120974</td>\n",
       "      <td>51.530100</td>\n",
       "      <td>530436.760</td>\n",
       "      <td>182911.990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Sedding Street, Sloane Square</td>\n",
       "      <td>-0.156876</td>\n",
       "      <td>51.493100</td>\n",
       "      <td>528051.649</td>\n",
       "      <td>178742.097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>Broadcasting House, Marylebone</td>\n",
       "      <td>-0.144229</td>\n",
       "      <td>51.518100</td>\n",
       "      <td>528857.440</td>\n",
       "      <td>181542.870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Charlbert Street, St. John's Wood</td>\n",
       "      <td>-0.168074</td>\n",
       "      <td>51.534300</td>\n",
       "      <td>527158.010</td>\n",
       "      <td>183300.750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Maida Vale, Maida Vale</td>\n",
       "      <td>-0.183486</td>\n",
       "      <td>51.529857</td>\n",
       "      <td>526102.000</td>\n",
       "      <td>182780.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>New Globe Walk, Bankside</td>\n",
       "      <td>-0.096441</td>\n",
       "      <td>51.507400</td>\n",
       "      <td>532203.970</td>\n",
       "      <td>180434.550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>Park Street, Bankside</td>\n",
       "      <td>-0.092754</td>\n",
       "      <td>51.506000</td>\n",
       "      <td>532463.890</td>\n",
       "      <td>180284.300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Station.Id                           StationName  longitude   latitude  \\\n",
       "0           1             River Street, Clerkenwell  -0.109971  51.529200   \n",
       "1           2        Phillimore Gardens, Kensington  -0.197574  51.499600   \n",
       "2           3  Christopher Street, Liverpool Street  -0.084606  51.521300   \n",
       "3           4       St. Chad's Street, King's Cross  -0.120974  51.530100   \n",
       "4           5         Sedding Street, Sloane Square  -0.156876  51.493100   \n",
       "5           6        Broadcasting House, Marylebone  -0.144229  51.518100   \n",
       "6           7     Charlbert Street, St. John's Wood  -0.168074  51.534300   \n",
       "7           8                Maida Vale, Maida Vale  -0.183486  51.529857   \n",
       "8           9              New Globe Walk, Bankside  -0.096441  51.507400   \n",
       "9          10                 Park Street, Bankside  -0.092754  51.506000   \n",
       "\n",
       "      Easting    Northing  \n",
       "0  531202.520  182832.020  \n",
       "1  525207.070  179391.860  \n",
       "2  532984.810  182001.530  \n",
       "3  530436.760  182911.990  \n",
       "4  528051.649  178742.097  \n",
       "5  528857.440  181542.870  \n",
       "6  527158.010  183300.750  \n",
       "7  526102.000  182780.000  \n",
       "8  532203.970  180434.550  \n",
       "9  532463.890  180284.300  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "station_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "808"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(station_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of stations is 808."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
       "        14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,\n",
       "        27,  28,  29,  30,  31,  32,  33,  34,  36,  37,  38,  39,  40,\n",
       "        41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,\n",
       "        54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,\n",
       "        67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,  78,  79,\n",
       "        80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,  92,\n",
       "        93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105,\n",
       "       106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118,\n",
       "       119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131,\n",
       "       132, 133, 134, 135, 136, 138, 139, 140, 141, 142, 143, 144, 145,\n",
       "       146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158,\n",
       "       159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171,\n",
       "       172, 173, 174, 175, 176, 177, 178, 180, 181, 182, 183, 184, 185,\n",
       "       186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 199,\n",
       "       200, 201, 202, 203, 204, 206, 207, 208, 209, 210, 211, 212, 213,\n",
       "       214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226,\n",
       "       227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239,\n",
       "       240, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253,\n",
       "       254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266,\n",
       "       267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279,\n",
       "       280, 281, 282, 283, 284, 286, 287, 288, 289, 290, 291, 292, 293,\n",
       "       294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 305, 306, 307,\n",
       "       308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320,\n",
       "       321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333,\n",
       "       334, 335, 336, 337, 338, 339, 340, 341, 343, 344, 345, 347, 348,\n",
       "       349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361,\n",
       "       362, 363, 364, 365, 366, 367, 368, 370, 371, 372, 373, 374, 375,\n",
       "       376, 377, 378, 379, 380, 381, 382, 383, 384, 386, 387, 388, 389,\n",
       "       390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402,\n",
       "       403, 404, 405, 408, 409, 410, 411, 412, 419, 420, 421, 423, 424,\n",
       "       425, 426, 427, 428, 430, 431, 432, 433, 435, 436, 437, 439, 440,\n",
       "       441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453,\n",
       "       454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466,\n",
       "       467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479,\n",
       "       480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492,\n",
       "       494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506,\n",
       "       507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519,\n",
       "       520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532,\n",
       "       533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545,\n",
       "       546, 547, 548, 549, 550, 551, 552, 553, 554, 556, 557, 558, 559,\n",
       "       560, 561, 562, 563, 564, 565, 566, 568, 569, 570, 571, 572, 573,\n",
       "       574, 576, 577, 578, 579, 580, 581, 583, 584, 586, 587, 588, 589,\n",
       "       590, 591, 592, 593, 594, 595, 596, 597, 598, 599, 600, 601, 602,\n",
       "       603, 604, 605, 606, 607, 608, 609, 610, 611, 612, 613, 614, 615,\n",
       "       616, 617, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628,\n",
       "       629, 630, 631, 632, 633, 634, 635, 636, 637, 638, 639, 640, 641,\n",
       "       642, 643, 644, 645, 646, 647, 648, 649, 650, 651, 652, 653, 654,\n",
       "       655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667,\n",
       "       668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680,\n",
       "       681, 682, 683, 684, 685, 686, 687, 688, 689, 690, 691, 692, 693,\n",
       "       694, 695, 696, 697, 698, 699, 700, 701, 702, 703, 704, 705, 706,\n",
       "       707, 708, 709, 710, 711, 712, 713, 714, 715, 716, 717, 718, 719,\n",
       "       720, 721, 722, 723, 724, 725, 726, 727, 728, 729, 730, 731, 732,\n",
       "       733, 734, 735, 736, 737, 738, 739, 740, 741, 742, 743, 744, 745,\n",
       "       746, 747, 748, 749, 750, 751, 752, 753, 754, 755, 756, 757, 758,\n",
       "       759, 760, 761, 762, 763, 764, 765, 766, 767, 768, 769, 770, 771,\n",
       "       772, 773, 774, 775, 776, 777, 778, 779, 780, 781, 782, 783, 784,\n",
       "       785, 786, 787, 788, 789, 790, 792, 793, 794, 795, 796, 797, 798,\n",
       "       799, 800, 801, 802, 803, 804, 805, 806, 807, 808, 809, 810, 811,\n",
       "       812, 813, 814, 815, 816, 817, 818, 819, 820, 821, 826, 827, 828,\n",
       "       829, 830, 831, 832, 833, 834, 835, 836, 838, 839, 840, 841, 842,\n",
       "       844, 845])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "station_data['Station.Id'].to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The leftmost column in bold gives the index of the table. It is not the same as Station ID, which is given by the column named 'Station.Id'. But we could always access entries by Station ID, or by the table ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([261], dtype='int64')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Access by Station ID\n",
    "station_data[station_data['Station.Id'] == 268].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Station.Id                         268\n",
       "StationName    Belgrave Road, Victoria\n",
       "longitude                    -0.144133\n",
       "latitude                       51.4932\n",
       "Easting                      528934.35\n",
       "Northing                     178772.58\n",
       "Name: 261, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Access by Table ID\n",
    "station_data.iloc[261]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the station Belgrave Road, Victoria, its station ID is 268, but its table ID is 261."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([43], dtype='int64')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Access by Station ID\n",
    "station_data[station_data['StationName'] == \"Boston Place, Marylebone\"].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Station.Id                                 798\n",
       "StationName    Birkenhead Street, King's Cross\n",
       "longitude                            -0.122299\n",
       "latitude                               51.5302\n",
       "Easting                               530345.0\n",
       "Northing                              182925.0\n",
       "Name: 766, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Access by Table ID\n",
    "station_data.iloc[766]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below gives a collection of bike stations near National Railway stations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Station names | Station ID | DF Index | \n",
    "| --- | --- | --- |\n",
    "| Belgrave Road, Victoria | 268 | 261 |\n",
    "| Waterloo Station 1, Waterloo | 374 | 362 |\n",
    "| Waterloo Station 2, Waterloo | 261 | 350 |\n",
    "| Waterloo Station 3, Waterloo | 154 | 151 |\n",
    "| South Wharf Road, Paddington | 186 | 182 |\n",
    "| Birkenhead Street, King's Cross | 798 | 766 |\n",
    "| Snowsfields, London Bridge | 706 | 675 |\n",
    "| Boston Place, Marylebone | 45 | 43 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now do some processing of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "max(station_data['Station.Id']), len(np.unique(station_data['Station.Id']))\n",
    "station_ID = list(station_data['Station.Id'])\n",
    "row_no = list(range(len(station_data['Station.Id'])))\n",
    "row_ID_dict = dict(zip(station_ID, row_no))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OptimizationError(RuntimeError):\n",
    "    \"\"\"Called when optimizer does not converge.\"\"\"\n",
    "    pass\n",
    "\n",
    "class StationIdError(IndexError):\n",
    "    \"\"\"Called when we try and read a non-existing station id.\"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We write a function to obtain station name corresponding to a given station ID number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_station_name(in_id):\n",
    "    \"\"\"Get station name from bike_data for a given id.\"\"\"\n",
    "    try:\n",
    "        return station_data[station_data[\"Station.Id\"] == in_id].StationName.iloc[0]\n",
    "    except IndexError:\n",
    "        StationIdError(\"No station matching input ID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Sidney Road, Stockwell'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_station_name(830)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get the longitude and latitude data in radians from the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_9/b_735jv1185f9snmzn_j6bjw0000gn/T/ipykernel_68253/3272816846.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  station_coord['longitude_radians'] = station_coord['longitude'].apply(lambda x: radians(x))\n",
      "/var/folders/_9/b_735jv1185f9snmzn_j6bjw0000gn/T/ipykernel_68253/3272816846.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  station_coord['latitude_radians'] = station_coord['latitude'].apply(lambda x: radians(x))\n"
     ]
    }
   ],
   "source": [
    "from math import radians\n",
    "station_coord = station_data[[\"longitude\",\"latitude\"]]\n",
    "station_coord['longitude_radians'] = station_coord['longitude'].apply(lambda x: radians(x)) \n",
    "station_coord['latitude_radians'] = station_coord['latitude'].apply(lambda x: radians(x)) \n",
    "station_coord = station_coord[['latitude_radians','longitude_radians']].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 8.99354201e-01, -1.91935603e-03],\n",
       "       [ 8.98837583e-01, -3.44831682e-03],\n",
       "       [ 8.99216320e-01, -1.47664803e-03],\n",
       "       ...,\n",
       "       [ 8.99038384e-01, -1.89027885e-03],\n",
       "       [ 8.98821928e-01, -8.56206171e-04],\n",
       "       [ 8.98811351e-01, -1.10744632e-03]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "station_coord"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we find the geodesic distance between each station, using the haversine formula."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jigglypuffy/Documents/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_distance_metric.py:10: FutureWarning: sklearn.neighbors.DistanceMetric has been moved to sklearn.metrics.DistanceMetric in 1.0. This import path will be removed in 1.3\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "8.174215894780051"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dist = DistanceMetric.get_metric('haversine')\n",
    "geo_dist = dist.pairwise(station_coord) * 6365.079\n",
    "geo_dist_df = pd.DataFrame(geo_dist)\n",
    "geo_dist_df.iloc[1,2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We save the geodesic distance between each pair of stations into an array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        ,  6.891488  ,  1.9605899 , ...,  2.01349835,\n",
       "         5.4049247 ,  4.72041716],\n",
       "       [ 6.891488  ,  0.        ,  8.17421589, ...,  6.30370511,\n",
       "        10.271535  ,  9.27709531],\n",
       "       [ 1.9605899 ,  8.17421589,  0.        , ...,  1.99173004,\n",
       "         3.51324925,  2.96369879],\n",
       "       ...,\n",
       "       [ 2.01349835,  6.30370511,  1.99173004, ...,  0.        ,\n",
       "         4.32238187,  3.42167331],\n",
       "       [ 5.4049247 , 10.271535  ,  3.51324925, ...,  4.32238187,\n",
       "         0.        ,  0.99781121],\n",
       "       [ 4.72041716,  9.27709531,  2.96369879, ...,  3.42167331,\n",
       "         0.99781121,  0.        ]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "geo_dist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We save the geodesic dataframe into csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "geo_dist_df.to_csv('../Data/geodesic.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We read the bike data folder, create a dictionary, store the file name as key and the data frame inside the file as value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   start_loc  end_loc   start_t  duration\n",
      "0         47       56  55728000      1500\n",
      "1        762      600  55728000       540\n",
      "2        588      698  55728060       420\n",
      "3        456      456  55728120     12240\n",
      "4         67       67  55728120       660\n"
     ]
    }
   ],
   "source": [
    "path = '../Data/santander_summaries'\n",
    "data_files = os.listdir(path)\n",
    "n_weeks = len(data_files)\n",
    "bike_data = {file: pd.read_csv(path + '/' + file,\n",
    "                                     names=[\"start_loc\", \"end_loc\",\n",
    "                                            \"start_t\", \"duration\"])\n",
    "             for file in data_files}        \n",
    "\n",
    "print(list(bike_data.values())[0].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we sort the data according to start time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'221_01Jul2020-07Jul2020.csv':         start_loc  end_loc   start_t  duration\n",
      "0             103       37  47260920       360\n",
      "1              39      539  47260920       120\n",
      "2             785      785  47260920       300\n",
      "3             341      159  47260980      1800\n",
      "4             708      573  47260980      1080\n",
      "...           ...      ...       ...       ...\n",
      "248194        270      272  47864700       480\n",
      "248195        117      152  47864760       480\n",
      "248196        171      155  47864760       180\n",
      "248197         83      826  47864820       540\n",
      "248198        154      173  47864940       300\n",
      "\n",
      "[248199 rows x 4 columns], '222_08Jul2020-14Jul2020.csv':         start_loc  end_loc   start_t  duration\n",
      "0             517      531  47865600       180\n",
      "1             532      476  47865600       780\n",
      "2             797      201  47865660       600\n",
      "3             779      508  47865660       960\n",
      "4             797      312  47865660       900\n",
      "...           ...      ...       ...       ...\n",
      "254142        167      826  48469920       300\n",
      "254143         92      297  48469920       180\n",
      "254144        118      177  48470040       300\n",
      "254145        356      163  48470040       240\n",
      "254146        426      267  48470100        60\n",
      "\n",
      "[254147 rows x 4 columns], '223_15Jul2020-21Jul2020.csv':         start_loc  end_loc   start_t  duration\n",
      "0             130      479  48470400      1080\n",
      "1             163      183  48470400       660\n",
      "2             130      479  48470400      1140\n",
      "3             130      479  48470400      1140\n",
      "4             130      479  48470400      1080\n",
      "...           ...      ...       ...       ...\n",
      "284329         77       25  49074600       480\n",
      "284330        446      517  49074600       480\n",
      "284331        814      100  49074600       360\n",
      "284332        772      827  49074720       420\n",
      "284333        402      410  49074900       240\n",
      "\n",
      "[284334 rows x 4 columns], '224_22Jul2020-28Jul2020.csv':         start_loc  end_loc   start_t  duration\n",
      "0             301      514  49075200       600\n",
      "1             692      719  49075200       840\n",
      "2             446      553  49075200       240\n",
      "3             524      701  49075260      1260\n",
      "4             192      762  49075260       480\n",
      "...           ...      ...       ...       ...\n",
      "239870        121      201  49679460       180\n",
      "239871        132      533  49679520       300\n",
      "239872        505      505  49679580       120\n",
      "239873        296      216  49679580       360\n",
      "239874        381      357  49679760       120\n",
      "\n",
      "[239875 rows x 4 columns], '225_29Jul2020-04Aug2020.csv':         start_loc  end_loc   start_t  duration\n",
      "0             786      784  49680000       120\n",
      "1             264      695  49680000       780\n",
      "2             348      733  49680000       480\n",
      "3             272      194  49680000      1500\n",
      "4             517      470  49680000       300\n",
      "...           ...      ...       ...       ...\n",
      "294982        119       95  50284320       300\n",
      "294983        633      635  50284380       120\n",
      "294984        492      505  50284380       180\n",
      "294985        148      190  50284380       240\n",
      "294986         14      793  50284500       120\n",
      "\n",
      "[294987 rows x 4 columns], '226_05Aug2020-11Aug2020.csv':         start_loc  end_loc   start_t  duration\n",
      "0             610      419  50284800       840\n",
      "1             194      722  50284800      1440\n",
      "2             192      311  50284800       420\n",
      "3             466       62  50284800      1860\n",
      "4             281       69  50284800       900\n",
      "...           ...      ...       ...       ...\n",
      "298072        326      697  50889000       420\n",
      "298073        130      200  50889120       420\n",
      "298074        485      459  50889120       360\n",
      "298075        130      200  50889180       360\n",
      "298076        190      426  50889180       120\n",
      "\n",
      "[298077 rows x 4 columns], '227_12Aug2020-18Aug2020.csv':         start_loc  end_loc   start_t  duration\n",
      "0             804      818  50889600       840\n",
      "1             377      670  50889600      2040\n",
      "2             177      641  50889600      1380\n",
      "3             278      732  50889600       660\n",
      "4             329      343  50889600       420\n",
      "...           ...      ...       ...       ...\n",
      "238369         32       39  51493740       240\n",
      "238370        615      607  51493800       240\n",
      "238371        272       80  51493860       240\n",
      "238372        577      478  51494040       300\n",
      "238373        478      450  51494040       240\n",
      "\n",
      "[238374 rows x 4 columns], '228_19Aug2020-25Aug2020.csv':         start_loc  end_loc   start_t  duration\n",
      "0             282      772  51494400      2460\n",
      "1              91      614  51494400       660\n",
      "2             480      561  51494400       300\n",
      "3             252      252  51494400      1200\n",
      "4               3      262  51494400       600\n",
      "...           ...      ...       ...       ...\n",
      "236543        411      223  52098660       420\n",
      "236544        533      322  52098660       180\n",
      "236545        553      717  52098720       180\n",
      "236546        633      635  52098780       180\n",
      "236547        660      761  52098840       300\n",
      "\n",
      "[236548 rows x 4 columns], '229_26Aug2020-01Sep2020.csv':         start_loc  end_loc   start_t  duration\n",
      "0             192      234  52099200      1380\n",
      "1             192      234  52099200      1320\n",
      "2             492      478  52099200       300\n",
      "3             195      321  52099200       780\n",
      "4             723      671  52099200       480\n",
      "...           ...      ...       ...       ...\n",
      "230061        606      652  52703340       240\n",
      "230062        458      488  52703400        60\n",
      "230063        442      442  52703460       480\n",
      "230064        202      511  52703640       300\n",
      "230065        367       56  52703640       240\n",
      "\n",
      "[230066 rows x 4 columns], '230_02Sep2020-08Sep2020.csv':         start_loc  end_loc   start_t  duration\n",
      "0             798      798  52704000      1380\n",
      "1             246       30  52704000       240\n",
      "2              69      333  52704000       900\n",
      "3             798      798  52704000      1380\n",
      "4             785       17  52704000      2460\n",
      "...           ...      ...       ...       ...\n",
      "249098        452      453  53308200       480\n",
      "249099        329      286  53308260       480\n",
      "249100        268      190  53308320       240\n",
      "249101        732      732  53308440       300\n",
      "249102        553      479  53308500       240\n",
      "\n",
      "[249103 rows x 4 columns], '231_09Sep2020-15Sep2020.csv':         start_loc  end_loc   start_t  duration\n",
      "0             491      446  53308800       780\n",
      "1             776      267  53308800      1260\n",
      "2             428      219  53308800       540\n",
      "3             457      457  53308800        60\n",
      "4             611      301  53308800      1560\n",
      "...           ...      ...       ...       ...\n",
      "283513        810      810  53913060        60\n",
      "283514        115      715  53913060       480\n",
      "283515        573      610  53913180       300\n",
      "283516        356      219  53913180       360\n",
      "283517        573      610  53913240       240\n",
      "\n",
      "[283518 rows x 4 columns], '232_16Sep2020-22Sep2020.csv':         start_loc  end_loc   start_t  duration\n",
      "0             588      465  53913600       360\n",
      "1             411      317  53913600      1860\n",
      "2             542      510  53913600     15600\n",
      "3              86      691  53913600      4800\n",
      "4             411      317  53913600      1860\n",
      "...           ...      ...       ...       ...\n",
      "307588        249      249  54517740       480\n",
      "307589        774      723  54517740       420\n",
      "307590        565       40  54517920       360\n",
      "307591        775      667  54517980       240\n",
      "307592        775      667  54518040       180\n",
      "\n",
      "[307593 rows x 4 columns], '233_23Sep2020-29Sep2020.csv':         start_loc  end_loc   start_t  duration\n",
      "0              68      135  54518400       240\n",
      "1             314      420  54518400       720\n",
      "2              32       86  54518400      1440\n",
      "3             171      618  54518520       600\n",
      "4             225       38  54518580      1200\n",
      "...           ...      ...       ...       ...\n",
      "217932        720      655  55122600       480\n",
      "217933        503      505  55122600       480\n",
      "217934        645      548  55122660       300\n",
      "217935        720      655  55122720       360\n",
      "217936        720      655  55122720       360\n",
      "\n",
      "[217937 rows x 4 columns], '234_30Sep2020-06Oct2020.csv':         start_loc  end_loc   start_t  duration\n",
      "0             430      573  55123200       180\n",
      "1             220      280  55123200      2760\n",
      "2             362      796  55123260       540\n",
      "3             706      692  55123260      1800\n",
      "4             721      787  55123260       660\n",
      "...           ...      ...       ...       ...\n",
      "158817        267      118  55727640       180\n",
      "158818        446      577  55727640       300\n",
      "158819        306      383  55727640       300\n",
      "158820        306      383  55727640       300\n",
      "158821        306      383  55727640       300\n",
      "\n",
      "[158822 rows x 4 columns], '235_07Oct2020-13Oct2020.csv':         start_loc  end_loc   start_t  duration\n",
      "0              47       56  55728000      1500\n",
      "1             762      600  55728000       540\n",
      "2             588      698  55728060       420\n",
      "3             456      456  55728120     12240\n",
      "4              67       67  55728120       660\n",
      "...           ...      ...       ...       ...\n",
      "201383        219      761  56332140       360\n",
      "201384        432      219  56332140       360\n",
      "201385         81      239  56332200       240\n",
      "201386        132      282  56332320       300\n",
      "201387        622      543  56332440       240\n",
      "\n",
      "[201388 rows x 4 columns], '236_14Oct2020-20Oct2020.csv':         start_loc  end_loc   start_t  duration\n",
      "0             456      535  56332800      1320\n",
      "1             448      101  56332800      1740\n",
      "2             691      628  56332800       420\n",
      "3              98       34  56332800       420\n",
      "4             828      609  56332860      1020\n",
      "...           ...      ...       ...       ...\n",
      "218130        217      115  56937120       240\n",
      "218131        561      522  56937180       360\n",
      "218132        449      450  56937240       240\n",
      "218133        245      245  56937300        60\n",
      "218134        731      737  56937360       120\n",
      "\n",
      "[218135 rows x 4 columns]}\n"
     ]
    }
   ],
   "source": [
    "bike_keys = sorted(bike_data)\n",
    "sorted_bike_data = {i: bike_data[i] for i in bike_keys}\n",
    " \n",
    "print(sorted_bike_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We map the row number to each location index in station_data, and add the distance column for each journey."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   start_loc  end_loc  distance        start_t          end_t   duration\n",
      "0        103       37  1.455347  787682.551083  787688.795509   6.244425\n",
      "1         39      539  0.544400  787682.077241  787685.010834   2.933593\n",
      "2        785      785  0.000000  787682.560881  787687.600020   5.039139\n",
      "3        341      159  1.090538  787683.229835  787713.351038  30.121203\n",
      "4        708      573  3.599904  787683.523229  787701.735893  18.212663\n",
      "5        366      138  0.463223  787684.637816  787691.852334   7.214519\n",
      "6         66      832  6.017458  787684.565727  787712.513200  27.947473\n",
      "7        225      384  1.459768  787685.867103  787693.156269   7.289166\n",
      "8        729      207  4.568847  787686.123903  787706.757129  20.633226\n",
      "9        510      763  1.334991  787686.698751  787692.041734   5.342983\n"
     ]
    }
   ],
   "source": [
    "bike_loc = dict(sorted_bike_data)\n",
    "\n",
    "for names in bike_loc.keys():\n",
    "    endt = np.zeros(bike_loc[names].shape[0], dtype = 'float64')\n",
    "    bike_loc[names] = bike_loc[names].to_numpy()\n",
    "    startt = bike_loc[names][:, 2].astype('float64')\n",
    "    dura = bike_loc[names][:, 3].astype('float64')\n",
    "    bike_loc[names] = bike_loc[names][:, 0:2]\n",
    "        \n",
    "    start_noise = np.random.uniform(0.0, 1.0, bike_loc[names].shape[0])\n",
    "    startt = startt / 60 + start_noise\n",
    "    duration_noise = np.random.uniform(0.0, 1.0, bike_loc[names].shape[0])\n",
    "    dura = dura / 60 + duration_noise\n",
    "    endt = startt + dura\n",
    "    \n",
    "    dist = np.zeros((bike_loc[names].shape[0], 1), dtype = geo_dist.dtype)\n",
    "    for r in range(bike_loc[names].shape[0]):\n",
    "            dist[r] = geo_dist[row_ID_dict[bike_loc[names][r, 0]], row_ID_dict[bike_loc[names][r, 1]]]\n",
    "    \n",
    "    dist = pd.DataFrame(dist)\n",
    "    startt = pd.DataFrame(startt)\n",
    "    endt = pd.DataFrame(endt)\n",
    "    dura = pd.DataFrame(dura)\n",
    "    bike_loc[names] = pd.DataFrame(bike_loc[names], columns = [\"start_loc\", \"end_loc\"])\n",
    "    \n",
    "    bike_loc[names] = bike_loc[names].assign(distance = dist)\n",
    "    bike_loc[names] = bike_loc[names].assign(start_t = startt)\n",
    "    bike_loc[names] = bike_loc[names].assign(end_t = endt)\n",
    "    bike_loc[names] = bike_loc[names].assign(duration = dura)\n",
    "    \n",
    "print(list(bike_loc.values())[0].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We repeat the above procedure, but normalise the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   start_loc  end_loc  distance   start_t      end_t   duration\n",
      "0        103       37  1.455347  2.443042   8.093304   5.650262\n",
      "1         39      539  0.544400  2.260985   4.093658   1.832673\n",
      "2        785      785  0.000000  2.337970   7.154192   4.816222\n",
      "3        341      159  1.090538  3.543996  33.499252  29.955256\n",
      "4        708      573  3.599904  3.843514  21.965196  18.121682\n",
      "5        366      138  0.463223  4.876573  11.522892   6.646319\n",
      "6         66      832  6.017458  4.673414  31.913564  27.240149\n",
      "7        225      384  1.459768  5.186432  12.867942   7.681510\n",
      "8        729      207  4.568847  6.641825  26.604163  19.962338\n",
      "9        510      763  1.334991  6.489251  11.890359   5.401108\n"
     ]
    }
   ],
   "source": [
    "bike_loc = dict(sorted_bike_data)\n",
    "\n",
    "for names in bike_loc.keys():\n",
    "    bike_loc[names] = bike_loc[names].to_numpy()\n",
    "    startt = bike_loc[names][:, 2].astype('float64')\n",
    "    dura = bike_loc[names][:, 3].astype('float64')\n",
    "    endt = startt + dura\n",
    "    bike_loc[names] = bike_loc[names][:, 0:2]\n",
    "    t_min = np.floor(47260920/(60*60*24))*60*60*24\n",
    "        \n",
    "    start_noise = np.random.uniform(0.0, 1.0, bike_loc[names].shape[0])\n",
    "    startt = (startt - t_min) / 60 + start_noise\n",
    "    end_noise = np.random.uniform(0.0, 1.0, bike_loc[names].shape[0])\n",
    "    endt = (endt - t_min) / 60 + end_noise\n",
    "    dura = endt - startt\n",
    "    \n",
    "    dist = np.zeros((bike_loc[names].shape[0], 1), dtype = geo_dist.dtype)\n",
    "    for r in range(bike_loc[names].shape[0]):\n",
    "            dist[r] = geo_dist[row_ID_dict[bike_loc[names][r, 0]], row_ID_dict[bike_loc[names][r, 1]]]\n",
    "    \n",
    "    dist = pd.DataFrame(dist)\n",
    "    startt = pd.DataFrame(startt)\n",
    "    endt = pd.DataFrame(endt)\n",
    "    dura = pd.DataFrame(dura)\n",
    "    bike_loc[names] = pd.DataFrame(bike_loc[names], columns = [\"start_loc\", \"end_loc\"])\n",
    "    \n",
    "    bike_loc[names] = bike_loc[names].assign(distance = dist)\n",
    "    bike_loc[names] = bike_loc[names].assign(start_t = startt)\n",
    "    bike_loc[names] = bike_loc[names].assign(end_t = endt)\n",
    "    bike_loc[names] = bike_loc[names].assign(duration = dura)\n",
    "    \n",
    "print(list(bike_loc.values())[0].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We obtain a dictionary containing all bike journeys that start from station ID 2, i.e., 'start_loc' == 2. And we also obtain a dictionary containing all bike journeys that end at station ID 2, i.e., 'end_loc' == 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      start_loc  end_loc  distance     start_t       end_t    duration\n",
      "423           2        2  0.000000  138.852795  167.543995   28.691200\n",
      "424           2        2  0.000000  138.903072  164.805069   25.901997\n",
      "428           2        2  0.000000  139.193403  166.678777   27.485374\n",
      "3910          2      558  4.882449  511.119333  550.057092   38.937758\n",
      "3983          2      228  4.438654  513.513071  530.892008   17.378937\n",
      "4071          2      219  1.156326  516.240557  536.137712   19.897155\n",
      "4089          2      219  1.156326  516.635117  536.964413   20.329295\n",
      "4189          2      389  3.117940  519.750296  533.137913   13.387617\n",
      "4454          2      826  3.789855  528.121062  948.139151  420.018089\n",
      "5182          2      348  3.544449  553.314412  573.607162   20.292750\n",
      "      start_loc  end_loc  distance     start_t       end_t   duration\n",
      "423           2        2  0.000000  138.852795  167.543995  28.691200\n",
      "424           2        2  0.000000  138.903072  164.805069  25.901997\n",
      "428           2        2  0.000000  139.193403  166.678777  27.485374\n",
      "645         164        2  2.039204  327.022923  338.804044  11.781121\n",
      "1717        687        2  0.985429  434.764117  443.918992   9.154875\n",
      "1902        296        2  0.822637  442.341981  450.252015   7.910034\n",
      "2218        190        2  4.602125  454.744695  478.411509  23.666814\n",
      "2984        219        2  1.156326  482.222414  496.182221  13.959807\n",
      "3003        181        2  3.129843  483.433870  499.043079  15.609209\n",
      "3008        219        2  1.156326  483.819562  496.354291  12.534728\n"
     ]
    }
   ],
   "source": [
    "data_dict_dep = {}\n",
    "data_dict_arr = {}\n",
    "\n",
    "for names in bike_loc.keys():\n",
    "    data_dict_dep[names] = bike_loc[names].loc[bike_loc[names]['start_loc'] == 2]\n",
    "    data_dict_arr[names] = bike_loc[names].loc[bike_loc[names]['end_loc'] == 2]\n",
    "        \n",
    "print(list(data_dict_dep.values())[0].head(10));\n",
    "print(list(data_dict_arr.values())[0].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We save the departure times data and the arrival times data into a new folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('../Processed_Data/SortDepartures', exist_ok=True)  \n",
    "\n",
    "for names in data_dict_dep.keys():\n",
    "    data_dict_dep[names].to_csv('../Processed_Data/Departures/'+ str(names))\n",
    "\n",
    "os.makedirs('../Processed_Data/SortArrivals', exist_ok=True)  \n",
    "\n",
    "for names in data_dict_arr.keys():\n",
    "    data_dict_arr[names].to_csv('../Processed_Data/Arrivals/'+ str(names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We obtain a dictionary containing all bike journeys that start from station ID 2, 3, 4, 5, i.e., 'start_loc' == 2,3, 4, 5. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      start_loc  end_loc  distance     start_t       end_t    duration\n",
      "423           2        2  0.000000  138.852795  167.543995   28.691200\n",
      "424           2        2  0.000000  138.903072  164.805069   25.901997\n",
      "428           2        2  0.000000  139.193403  166.678777   27.485374\n",
      "3910          2      558  4.882449  511.119333  550.057092   38.937758\n",
      "3983          2      228  4.438654  513.513071  530.892008   17.378937\n",
      "4071          2      219  1.156326  516.240557  536.137712   19.897155\n",
      "4089          2      219  1.156326  516.635117  536.964413   20.329295\n",
      "4189          2      389  3.117940  519.750296  533.137913   13.387617\n",
      "4454          2      826  3.789855  528.121062  948.139151  420.018089\n",
      "5182          2      348  3.544449  553.314412  573.607162   20.292750\n",
      "       start_loc  end_loc  distance      start_t        end_t   duration\n",
      "3999           3       57  2.470578   514.554357   527.217754  12.663397\n",
      "7170           3        3  0.000000   641.242302   658.750099  17.507797\n",
      "8137           3      776  8.855851   687.715041   736.048172  48.333131\n",
      "9731           3      101  1.221951   746.528810   751.656858   5.128047\n",
      "10361          3      502  2.768781   767.401006   782.475989  15.074983\n",
      "12851          3      463  1.738574   854.612561   863.538285   8.925724\n",
      "14763          3      308  2.467323   929.456799   944.042455  14.585656\n",
      "16350          3      732  1.676470   979.464480   987.866397   8.401917\n",
      "17111          3      645  2.432541  1001.362794  1017.661544  16.298750\n",
      "17282          3      374  2.790247  1005.982941  1022.011627  16.028687\n",
      "       start_loc  end_loc  distance     start_t       end_t    duration\n",
      "4522           4      256  1.855968  530.288778  540.089770    9.800992\n",
      "5245           4      194  3.478465  555.983879  570.175521   14.191642\n",
      "5923           4       49  3.081969  582.266098  603.376286   21.110188\n",
      "8177           4       14  0.184006  689.091025  759.135452   70.044427\n",
      "8276           4      592  4.574434  692.446843  845.816297  153.369454\n",
      "8811           4       11  0.685838  713.638326  718.218855    4.580529\n",
      "9898           4      364  1.397103  752.890704  762.094033    9.203329\n",
      "10949          4      795  0.998342  788.755257  796.345683    7.590426\n",
      "10963          4      795  0.998342  788.843146  796.203525    7.360378\n",
      "12017          4      377  2.790194  824.247632  837.955168   13.707536\n",
      "      start_loc  end_loc  distance     start_t       end_t   duration\n",
      "2286          5      821  1.239477  457.149589  536.692077  79.542488\n",
      "3420          5      430  1.349425  496.532703  506.609625  10.076922\n",
      "4261          5      776  3.710905  522.729252  546.484026  23.754774\n",
      "4797          5      143  0.517507  539.156512  542.053650   2.897138\n",
      "5618          5      256  3.588919  570.443117  604.222501  33.779384\n",
      "5973          5      167  0.647687  584.696194  588.626964   3.930771\n",
      "6662          5      345  0.894282  617.621055  621.406973   3.785918\n",
      "7513          5      201  3.290270  660.138623  687.135864  26.997241\n",
      "7525          5      201  3.290270  660.443734  687.597553  27.153819\n",
      "8445          5      648  3.820739  700.206859  721.405914  21.199055\n"
     ]
    }
   ],
   "source": [
    "loc_codes = [2, 3, 4, 5]\n",
    "data_dict_0 = {}\n",
    "data_dict_1 = {}\n",
    "data_dict_2 = {}\n",
    "data_dict_3 = {}\n",
    "\n",
    "for names in bike_loc.keys():\n",
    "    data_dict_0[names] = bike_loc[names].loc[bike_loc[names]['start_loc'] == 2]\n",
    "    data_dict_1[names] = bike_loc[names].loc[bike_loc[names]['start_loc'] == 3]\n",
    "    data_dict_2[names] = bike_loc[names].loc[bike_loc[names]['start_loc'] == 4]\n",
    "    data_dict_3[names] = bike_loc[names].loc[bike_loc[names]['start_loc'] == 5]\n",
    "        \n",
    "print(list(data_dict_0.values())[0].head(10));\n",
    "print(list(data_dict_1.values())[0].head(10))\n",
    "print(list(data_dict_2.values())[0].head(10))\n",
    "print(list(data_dict_3.values())[0].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We save the departure times data at each station into a new folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('./Station2', exist_ok=True)  \n",
    "\n",
    "for names in data_dict_dep.keys():\n",
    "    data_dict_0[names].to_csv('./Station2/'+ str(names))\n",
    "\n",
    "os.makedirs('./Station3', exist_ok=True)  \n",
    "\n",
    "for names in data_dict_arr.keys():\n",
    "    data_dict_1[names].to_csv('./Station3/'+ str(names))\n",
    "\n",
    "os.makedirs('./Station4', exist_ok=True)  \n",
    "\n",
    "for names in data_dict_arr.keys():\n",
    "    data_dict_2[names].to_csv('./Station4/'+ str(names))\n",
    "                                \n",
    "os.makedirs('./Station5', exist_ok=True)  \n",
    "\n",
    "for names in data_dict_arr.keys():\n",
    "    data_dict_3[names].to_csv('./Station5/'+ str(names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then read and save departure times at all stations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc_codes = station_data['Station.Id'].to_numpy()\n",
    "\n",
    "for i in range(808):\n",
    "    \n",
    "    loc = loc_codes[i]\n",
    "    data_dict = {}\n",
    "\n",
    "    for names in bike_loc.keys():\n",
    "        data_dict[names] = bike_loc[names].loc[bike_loc[names]['start_loc'] == loc]\n",
    "    \n",
    "    path = f\"../Processed_Data/sortdep/Station{loc}\"\n",
    "    os.makedirs(path, exist_ok=True) \n",
    "    \n",
    "    filename = f\"../Processed_Data/sortdep/Station{loc}/{str(names)}\"\n",
    "    for names in data_dict_dep.keys():\n",
    "        filename = f\"../Processed_Data/sortdep/Station{loc}/{str(names)}\"\n",
    "        data_dict[names].to_csv(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc_codes = station_data['Station.Id'].to_numpy()\n",
    "\n",
    "for i in range(808):\n",
    "    \n",
    "    loc = loc_codes[i]\n",
    "    data_dict = {}\n",
    "\n",
    "    for names in bike_loc.keys():\n",
    "        data_dict[names] = bike_loc[names].loc[bike_loc[names]['start_loc'] == loc]\n",
    "    \n",
    "    path = f\"../Processed_Data/sortarr/Station{loc}\"\n",
    "    os.makedirs(path, exist_ok=True) \n",
    "    \n",
    "    filename = f\"../Processed_Data/sortarr/Station{loc}/{str(names)}\"\n",
    "    for names in data_dict_dep.keys():\n",
    "        filename = f\"../Processed_Data/sortarr/Station{loc}/{str(names)}\"\n",
    "        data_dict[names].to_csv(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Add in duration.\n",
    "cols = [\"start_t\", \"end_t\",\"duration\",\"start_loc\", \"end_loc\"]\n",
    "for name in bike_data.keys():\n",
    "    bike_data[name] = bike_data[name].assign(end_t=lambda x:\n",
    "                                             abs(x.start_t + x.duration))\n",
    "    bike_data[name] = bike_data[name].reindex(columns=cols)\n",
    "\n",
    "print(list(bike_data.values())[0].head())\n",
    "\n",
    "#Map the row number to each location index in station_data.\n",
    "for name in bike_data.keys():\n",
    "    bike_data[name] = bike_data[name].to_numpy()\n",
    "    startno = np.zeros((bike_data[name].shape[0], 1), dtype=int)\n",
    "    endno = np.zeros((bike_data[name].shape[0], 1), dtype=int)\n",
    "    \n",
    "    for r in range(bike_data[name].shape[0]):\n",
    "        startno[r] = row_ID_dict[bike_data[name][r, 3]]\n",
    "        endno[r] = row_ID_dict[bike_data[name][r, 4]]\n",
    "    \n",
    "    startno = pd.DataFrame(startno)\n",
    "    endno = pd.DataFrame(endno)\n",
    "    bike_data[name] = pd.DataFrame(bike_data[name], columns = [\"start_t\", \"end_t\",\"duration\",\"start_loc\", \n",
    "                                                              \"end_loc\"])\n",
    "    \n",
    "    bike_data[name] = bike_data[name].assign(start_no = startno)\n",
    "    bike_data[name] = bike_data[name].assign(end_no = endno)\n",
    "    \n",
    "print(list(bike_data.values())[0].head())        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then we add the distance travelled for each journey."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    start_t     end_t  duration  start_loc  end_loc  distance\n",
      "0  55728000  55729500      1500         47       56  0.029266\n",
      "1  55728000  55728540       540        762      600  0.019513\n",
      "2  55728060  55728480       420        588      698  0.013609\n",
      "3  55728120  55740360     12240        456      456  0.000000\n",
      "4  55728120  55728780       660         67       67  0.000000\n",
      "5  55728120  55728420       300        243       74  0.015976\n",
      "6  55728180  55728480       300        715      444  0.011863\n",
      "7  55728180  55740420     12240        456      456  0.000000\n",
      "8  55728180  55740420     12240        456      456  0.000000\n",
      "9  55728180  55728600       420        383       83  0.003483\n"
     ]
    }
   ],
   "source": [
    "#Adding the distance column for each journey\n",
    "bike_loc = dict(bike_data)\n",
    "\n",
    "for names in bike_loc.keys():\n",
    "    bike_loc[names] = bike_loc[names].to_numpy()\n",
    "     \n",
    "    \n",
    "    dist = np.zeros((bike_loc[names].shape[0], 1), dtype = geo_dist.dtype)\n",
    "    for r in range(bike_loc[names].shape[0]):\n",
    "            dist[r] = geo_dist[bike_loc[names][r, 5], bike_loc[names][r, 6]]\n",
    "    \n",
    "    dist = pd.DataFrame(dist)\n",
    "    bike_loc[names] = pd.DataFrame(bike_loc[names], columns = [\"start_t\", \"end_t\",\"duration\",\"start_loc\", \n",
    "                                                              \"end_loc\", \"start_no\", \"end_no\"])\n",
    "    del bike_loc[names][\"start_no\"]\n",
    "    del bike_loc[names][\"end_no\"]\n",
    "    bike_loc[names] = bike_loc[names].assign(distance = dist)\n",
    "    \n",
    "print(list(bike_loc.values())[0].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we save the data into folders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
