{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import sys\n",
    "#!{sys.executable} -m pip install haversine\n",
    "import haversine \n",
    "from sklearn.neighbors import DistanceMetric\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use(\"dark_background\")\n",
    "plt.rcParams['figure.dpi'] = 150\n",
    "from nltk import flatten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We read the santander_locations document, which contains the location information of bike stations across London."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "station_data = pd.read_csv(\"./santander_locations.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Station.Id</th>\n",
       "      <th>StationName</th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>Easting</th>\n",
       "      <th>Northing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>River Street, Clerkenwell</td>\n",
       "      <td>-0.109971</td>\n",
       "      <td>51.529200</td>\n",
       "      <td>531202.520</td>\n",
       "      <td>182832.020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Phillimore Gardens, Kensington</td>\n",
       "      <td>-0.197574</td>\n",
       "      <td>51.499600</td>\n",
       "      <td>525207.070</td>\n",
       "      <td>179391.860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Christopher Street, Liverpool Street</td>\n",
       "      <td>-0.084606</td>\n",
       "      <td>51.521300</td>\n",
       "      <td>532984.810</td>\n",
       "      <td>182001.530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>St. Chad's Street, King's Cross</td>\n",
       "      <td>-0.120974</td>\n",
       "      <td>51.530100</td>\n",
       "      <td>530436.760</td>\n",
       "      <td>182911.990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Sedding Street, Sloane Square</td>\n",
       "      <td>-0.156876</td>\n",
       "      <td>51.493100</td>\n",
       "      <td>528051.649</td>\n",
       "      <td>178742.097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>Broadcasting House, Marylebone</td>\n",
       "      <td>-0.144229</td>\n",
       "      <td>51.518100</td>\n",
       "      <td>528857.440</td>\n",
       "      <td>181542.870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Charlbert Street, St. John's Wood</td>\n",
       "      <td>-0.168074</td>\n",
       "      <td>51.534300</td>\n",
       "      <td>527158.010</td>\n",
       "      <td>183300.750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Maida Vale, Maida Vale</td>\n",
       "      <td>-0.183486</td>\n",
       "      <td>51.529857</td>\n",
       "      <td>526102.000</td>\n",
       "      <td>182780.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>New Globe Walk, Bankside</td>\n",
       "      <td>-0.096441</td>\n",
       "      <td>51.507400</td>\n",
       "      <td>532203.970</td>\n",
       "      <td>180434.550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>Park Street, Bankside</td>\n",
       "      <td>-0.092754</td>\n",
       "      <td>51.506000</td>\n",
       "      <td>532463.890</td>\n",
       "      <td>180284.300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Station.Id                           StationName  longitude   latitude  \\\n",
       "0           1             River Street, Clerkenwell  -0.109971  51.529200   \n",
       "1           2        Phillimore Gardens, Kensington  -0.197574  51.499600   \n",
       "2           3  Christopher Street, Liverpool Street  -0.084606  51.521300   \n",
       "3           4       St. Chad's Street, King's Cross  -0.120974  51.530100   \n",
       "4           5         Sedding Street, Sloane Square  -0.156876  51.493100   \n",
       "5           6        Broadcasting House, Marylebone  -0.144229  51.518100   \n",
       "6           7     Charlbert Street, St. John's Wood  -0.168074  51.534300   \n",
       "7           8                Maida Vale, Maida Vale  -0.183486  51.529857   \n",
       "8           9              New Globe Walk, Bankside  -0.096441  51.507400   \n",
       "9          10                 Park Street, Bankside  -0.092754  51.506000   \n",
       "\n",
       "      Easting    Northing  \n",
       "0  531202.520  182832.020  \n",
       "1  525207.070  179391.860  \n",
       "2  532984.810  182001.530  \n",
       "3  530436.760  182911.990  \n",
       "4  528051.649  178742.097  \n",
       "5  528857.440  181542.870  \n",
       "6  527158.010  183300.750  \n",
       "7  526102.000  182780.000  \n",
       "8  532203.970  180434.550  \n",
       "9  532463.890  180284.300  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "station_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "808"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(station_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of stations is 808."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'station_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-3ada8c60a31f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mstation_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Station.Id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'station_data' is not defined"
     ]
    }
   ],
   "source": [
    "station_data['Station.Id'].to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The leftmost column in bold gives the index of the table. It is not the same as Station ID, which is given by the column named 'Station.Id'. But we could always access entries by Station ID, or by the table ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([261], dtype='int64')"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Access by Station ID\n",
    "station_data[station_data['Station.Id'] == 268].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Station.Id                         268\n",
       "StationName    Belgrave Road, Victoria\n",
       "longitude                    -0.144133\n",
       "latitude                       51.4932\n",
       "Easting                         528934\n",
       "Northing                        178773\n",
       "Name: 261, dtype: object"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Access by Table ID\n",
    "station_data.iloc[261]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the station Belgrave Road, Victoria, its station ID is 268, but its table ID is 261."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([43], dtype='int64')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Access by Station ID\n",
    "station_data[station_data['StationName'] == \"Boston Place, Marylebone\"].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Station.Id                                 798\n",
       "StationName    Birkenhead Street, King's Cross\n",
       "longitude                            -0.122299\n",
       "latitude                               51.5302\n",
       "Easting                                 530345\n",
       "Northing                                182925\n",
       "Name: 766, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Access by Table ID\n",
    "station_data.iloc[766]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below gives a collection of bike stations near National Railway stations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Station names | Station ID | DF Index | \n",
    "| --- | --- | --- |\n",
    "| Belgrave Road, Victoria | 268 | 261 |\n",
    "| Waterloo Station 1, Waterloo | 374 | 362 |\n",
    "| Waterloo Station 2, Waterloo | 261 | 350 |\n",
    "| Waterloo Station 3, Waterloo | 154 | 151 |\n",
    "| South Wharf Road, Paddington | 186 | 182 |\n",
    "| Birkenhead Street, King's Cross | 798 | 766 |\n",
    "| Snowsfields, London Bridge | 706 | 675 |\n",
    "| Boston Place, Marylebone | 45 | 43 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now do some processing of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "max(station_data['Station.Id']), len(np.unique(station_data['Station.Id']))\n",
    "station_ID = list(station_data['Station.Id'])\n",
    "row_no = list(range(len(station_data['Station.Id'])))\n",
    "row_ID_dict = dict(zip(station_ID, row_no))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OptimizationError(RuntimeError):\n",
    "    \"\"\"Called when optimizer does not converge.\"\"\"\n",
    "    pass\n",
    "\n",
    "class StationIdError(IndexError):\n",
    "    \"\"\"Called when we try and read a non-existing station id.\"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We write a function to obtain station name corresponding to a given station ID number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_station_name(in_id):\n",
    "    \"\"\"Get station name from bike_data for a given id.\"\"\"\n",
    "    try:\n",
    "        return station_data[station_data[\"Station.Id\"] == in_id].StationName.iloc[0]\n",
    "    except IndexError:\n",
    "        StationIdError(\"No station matching input ID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Sidney Road, Stockwell'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_station_name(830)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get the longitude and latitude data in radians from the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "from math import radians\n",
    "station_coord = station_data[[\"longitude\",\"latitude\"]]\n",
    "station_coord['longitude_radians'] = station_coord['longitude'].apply(lambda x: radians(x)) \n",
    "station_coord['latitude_radians'] = station_coord['latitude'].apply(lambda x: radians(x)) \n",
    "station_coord = station_coord[['latitude_radians','longitude_radians']].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 8.99354201e-01, -1.91935603e-03],\n",
       "       [ 8.98837583e-01, -3.44831682e-03],\n",
       "       [ 8.99216320e-01, -1.47664803e-03],\n",
       "       ...,\n",
       "       [ 8.99038384e-01, -1.89027885e-03],\n",
       "       [ 8.98821928e-01, -8.56206171e-04],\n",
       "       [ 8.98811351e-01, -1.10744632e-03]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "station_coord"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we find the geodesic distance between each station, using the haversine formula."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist = DistanceMetric.get_metric('haversine')\n",
    "geo_dist = dist.pairwise(station_coord) * 6365.079\n",
    "geo_dist_df = pd.DataFrame(geo_dist)\n",
    "geo_dist_df.iloc[1,2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We save the geodesic distance between each pair of stations into an array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        ,  6.891488  ,  1.9605899 , ...,  2.01349835,\n",
       "         5.4049247 ,  4.72041716],\n",
       "       [ 6.891488  ,  0.        ,  8.17421589, ...,  6.30370511,\n",
       "        10.271535  ,  9.27709531],\n",
       "       [ 1.9605899 ,  8.17421589,  0.        , ...,  1.99173004,\n",
       "         3.51324925,  2.96369879],\n",
       "       ...,\n",
       "       [ 2.01349835,  6.30370511,  1.99173004, ...,  0.        ,\n",
       "         4.32238187,  3.42167331],\n",
       "       [ 5.4049247 , 10.271535  ,  3.51324925, ...,  4.32238187,\n",
       "         0.        ,  0.99781121],\n",
       "       [ 4.72041716,  9.27709531,  2.96369879, ...,  3.42167331,\n",
       "         0.99781121,  0.        ]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "geo_dist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We save the geodesic dataframe into csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "geo_dist_df.to_csv('./geodesic.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We read the bike data folder, create a dictionary, store the file name as key and the data frame inside the file as value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   start_loc  end_loc   start_t  duration\n",
      "0         47       56  55728000      1500\n",
      "1        762      600  55728000       540\n",
      "2        588      698  55728060       420\n",
      "3        456      456  55728120     12240\n",
      "4         67       67  55728120       660\n"
     ]
    }
   ],
   "source": [
    "path = './santander_summaries'\n",
    "data_files = os.listdir(path)\n",
    "n_weeks = len(data_files)\n",
    "bike_data = {file: pd.read_csv(path + '/' + file,\n",
    "                                     names=[\"start_loc\", \"end_loc\",\n",
    "                                            \"start_t\", \"duration\"])\n",
    "             for file in data_files}        \n",
    "\n",
    "print(list(bike_data.values())[0].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we sort the data according to start time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'bike_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-d7ddfde18caa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbike_keys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbike_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0msorted_bike_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbike_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbike_keys\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msorted_bike_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'bike_data' is not defined"
     ]
    }
   ],
   "source": [
    "bike_keys = sorted(bike_data)\n",
    "sorted_bike_data = {i: bike_data[i] for i in bike_keys}\n",
    " \n",
    "print(sorted_bike_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We map the row number to each location index in station_data, and add the distance column for each journey."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   start_loc  end_loc  distance        start_t          end_t   duration\n",
      "0        103       37  1.455347  787682.433041  787689.133564   6.700523\n",
      "1         39      539  0.544400  787682.524014  787685.358116   2.834102\n",
      "2        785      785  0.000000  787682.465639  787688.043628   5.577989\n",
      "3        341      159  1.090538  787683.657119  787714.656619  30.999500\n",
      "4        708      573  3.599904  787683.240691  787702.209320  18.968630\n",
      "5        366      138  0.463223  787684.859478  787692.471952   7.612474\n",
      "6         66      832  6.017458  787684.177849  787711.647774  27.469925\n",
      "7        225      384  1.459768  787685.716766  787692.953482   7.236715\n",
      "8        729      207  4.568847  787686.183963  787706.512693  20.328729\n",
      "9        510      763  1.334991  787686.003770  787691.893567   5.889797\n"
     ]
    }
   ],
   "source": [
    "bike_loc = dict(sorted_bike_data)\n",
    "\n",
    "for names in bike_loc.keys():\n",
    "    endt = np.zeros(bike_loc[names].shape[0], dtype = 'float64')\n",
    "    bike_loc[names] = bike_loc[names].to_numpy()\n",
    "    startt = bike_loc[names][:, 2].astype('float64')\n",
    "    dura = bike_loc[names][:, 3].astype('float64')\n",
    "    bike_loc[names] = bike_loc[names][:, 0:2]\n",
    "        \n",
    "    start_noise = np.random.uniform(0.0, 1.0, bike_loc[names].shape[0])\n",
    "    startt = startt / 60 + start_noise\n",
    "    duration_noise = np.random.uniform(0.0, 1.0, bike_loc[names].shape[0])\n",
    "    dura = dura / 60 + duration_noise\n",
    "    endt = startt + dura\n",
    "    \n",
    "    dist = np.zeros((bike_loc[names].shape[0], 1), dtype = geo_dist.dtype)\n",
    "    for r in range(bike_loc[names].shape[0]):\n",
    "            dist[r] = geo_dist[row_ID_dict[bike_loc[names][r, 0]], row_ID_dict[bike_loc[names][r, 1]]]\n",
    "    \n",
    "    dist = pd.DataFrame(dist)\n",
    "    startt = pd.DataFrame(startt)\n",
    "    endt = pd.DataFrame(endt)\n",
    "    dura = pd.DataFrame(dura)\n",
    "    bike_loc[names] = pd.DataFrame(bike_loc[names], columns = [\"start_loc\", \"end_loc\"])\n",
    "    \n",
    "    bike_loc[names] = bike_loc[names].assign(distance = dist)\n",
    "    bike_loc[names] = bike_loc[names].assign(start_t = startt)\n",
    "    bike_loc[names] = bike_loc[names].assign(end_t = endt)\n",
    "    bike_loc[names] = bike_loc[names].assign(duration = dura)\n",
    "    \n",
    "print(list(bike_loc.values())[0].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We repeat the above procedure, but normalise the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   start_loc  end_loc  distance   start_t      end_t   duration\n",
      "0        103       37  1.455347  2.119259   8.670248   6.550988\n",
      "1         39      539  0.544400  2.140374   4.792660   2.652286\n",
      "2        785      785  0.000000  2.088577   7.816521   5.727944\n",
      "3        341      159  1.090538  3.504080  33.847014  30.342934\n",
      "4        708      573  3.599904  3.048540  21.242909  18.194369\n",
      "5        366      138  0.463223  4.027290  11.793456   7.766166\n",
      "6         66      832  6.017458  4.414472  31.792052  27.377580\n",
      "7        225      384  1.459768  5.242881  12.314880   7.072000\n",
      "8        729      207  4.568847  6.529955  26.907634  20.377679\n",
      "9        510      763  1.334991  6.181161  11.148302   4.967141\n"
     ]
    }
   ],
   "source": [
    "bike_loc = dict(sorted_bike_data)\n",
    "\n",
    "for names in bike_loc.keys():\n",
    "    bike_loc[names] = bike_loc[names].to_numpy()\n",
    "    startt = bike_loc[names][:, 2].astype('float64')\n",
    "    dura = bike_loc[names][:, 3].astype('float64')\n",
    "    endt = startt + dura\n",
    "    bike_loc[names] = bike_loc[names][:, 0:2]\n",
    "    t_min = np.floor(47260920/(60*60*24))*60*60*24\n",
    "        \n",
    "    start_noise = np.random.uniform(0.0, 1.0, bike_loc[names].shape[0])\n",
    "    startt = (startt - t_min) / 60 + start_noise\n",
    "    end_noise = np.random.uniform(0.0, 1.0, bike_loc[names].shape[0])\n",
    "    endt = (endt - t_min) / 60 + end_noise\n",
    "    dura = endt - startt\n",
    "    \n",
    "    dist = np.zeros((bike_loc[names].shape[0], 1), dtype = geo_dist.dtype)\n",
    "    for r in range(bike_loc[names].shape[0]):\n",
    "            dist[r] = geo_dist[row_ID_dict[bike_loc[names][r, 0]], row_ID_dict[bike_loc[names][r, 1]]]\n",
    "    \n",
    "    dist = pd.DataFrame(dist)\n",
    "    startt = pd.DataFrame(startt)\n",
    "    endt = pd.DataFrame(endt)\n",
    "    dura = pd.DataFrame(dura)\n",
    "    bike_loc[names] = pd.DataFrame(bike_loc[names], columns = [\"start_loc\", \"end_loc\"])\n",
    "    \n",
    "    bike_loc[names] = bike_loc[names].assign(distance = dist)\n",
    "    bike_loc[names] = bike_loc[names].assign(start_t = startt)\n",
    "    bike_loc[names] = bike_loc[names].assign(end_t = endt)\n",
    "    bike_loc[names] = bike_loc[names].assign(duration = dura)\n",
    "    \n",
    "print(list(bike_loc.values())[0].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We obtain a dictionary containing all bike journeys that start from station ID 2, i.e., 'start_loc' == 2. And we also obtain a dictionary containing all bike journeys that end at station ID 2, i.e., 'end_loc' == 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      start_loc  end_loc  distance     start_t       end_t    duration\n",
      "423           2        2  0.000000  138.390326  167.524228   29.133902\n",
      "424           2        2  0.000000  138.118309  164.339792   26.221483\n",
      "428           2        2  0.000000  139.168505  166.533031   27.364525\n",
      "3910          2      558  4.882449  511.574332  550.903712   39.329380\n",
      "3983          2      228  4.438654  513.149723  530.649633   17.499910\n",
      "4071          2      219  1.156326  516.339959  536.385236   20.045277\n",
      "4089          2      219  1.156326  516.786659  536.875989   20.089330\n",
      "4189          2      389  3.117940  519.214417  533.429633   14.215215\n",
      "4454          2      826  3.789855  528.408782  948.495018  420.086236\n",
      "5182          2      348  3.544449  553.272058  573.238550   19.966493\n",
      "      start_loc  end_loc  distance     start_t       end_t   duration\n",
      "423           2        2  0.000000  138.390326  167.524228  29.133902\n",
      "424           2        2  0.000000  138.118309  164.339792  26.221483\n",
      "428           2        2  0.000000  139.168505  166.533031  27.364525\n",
      "645         164        2  2.039204  327.182520  338.729403  11.546883\n",
      "1717        687        2  0.985429  434.499173  443.715833   9.216660\n",
      "1902        296        2  0.822637  442.790904  450.663907   7.873003\n",
      "2218        190        2  4.602125  454.554441  478.838980  24.284539\n",
      "2984        219        2  1.156326  482.074259  496.325307  14.251047\n",
      "3003        181        2  3.129843  483.461955  499.595540  16.133585\n",
      "3008        219        2  1.156326  483.284537  496.118510  12.833974\n"
     ]
    }
   ],
   "source": [
    "data_dict_dep = {}\n",
    "data_dict_arr = {}\n",
    "\n",
    "for names in bike_loc.keys():\n",
    "    data_dict_dep[names] = bike_loc[names].loc[bike_loc[names]['start_loc'] == 2]\n",
    "    data_dict_arr[names] = bike_loc[names].loc[bike_loc[names]['end_loc'] == 2]\n",
    "        \n",
    "print(list(data_dict_dep.values())[0].head(10));\n",
    "print(list(data_dict_arr.values())[0].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We save the departure times data and the arrival times data into a new folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('./SortDepartures', exist_ok=True)  \n",
    "\n",
    "for names in data_dict_dep.keys():\n",
    "    data_dict_dep[names].to_csv('./Departures/'+ str(names))\n",
    "\n",
    "os.makedirs('./SortArrivals', exist_ok=True)  \n",
    "\n",
    "for names in data_dict_arr.keys():\n",
    "    data_dict_arr[names].to_csv('./Arrivals/'+ str(names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We obtain a dictionary containing all bike journeys that start from station ID 2, 3, 4, 5, i.e., 'start_loc' == 2,3, 4, 5. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      start_loc  end_loc  distance     start_t       end_t    duration\n",
      "423           2        2  0.000000  138.390326  167.524228   29.133902\n",
      "424           2        2  0.000000  138.118309  164.339792   26.221483\n",
      "428           2        2  0.000000  139.168505  166.533031   27.364525\n",
      "3910          2      558  4.882449  511.574332  550.903712   39.329380\n",
      "3983          2      228  4.438654  513.149723  530.649633   17.499910\n",
      "4071          2      219  1.156326  516.339959  536.385236   20.045277\n",
      "4089          2      219  1.156326  516.786659  536.875989   20.089330\n",
      "4189          2      389  3.117940  519.214417  533.429633   14.215215\n",
      "4454          2      826  3.789855  528.408782  948.495018  420.086236\n",
      "5182          2      348  3.544449  553.272058  573.238550   19.966493\n",
      "       start_loc  end_loc  distance      start_t        end_t   duration\n",
      "3999           3       57  2.470578   514.570754   527.917456  13.346702\n",
      "7170           3        3  0.000000   641.234114   658.241234  17.007120\n",
      "8137           3      776  8.855851   687.992470   736.436382  48.443911\n",
      "9731           3      101  1.221951   746.960226   751.697064   4.736838\n",
      "10361          3      502  2.768781   767.875267   782.174251  14.298985\n",
      "12851          3      463  1.738574   854.631374   863.350188   8.718815\n",
      "14763          3      308  2.467323   929.772666   944.751117  14.978451\n",
      "16350          3      732  1.676470   979.585388   987.114103   7.528714\n",
      "17111          3      645  2.432541  1001.810451  1017.378003  15.567552\n",
      "17282          3      374  2.790247  1005.025848  1022.416023  17.390175\n",
      "       start_loc  end_loc  distance     start_t       end_t    duration\n",
      "4522           4      256  1.855968  530.506692  540.476334    9.969643\n",
      "5245           4      194  3.478465  555.451651  570.514358   15.062708\n",
      "5923           4       49  3.081969  582.485868  603.308642   20.822775\n",
      "8177           4       14  0.184006  689.869295  759.844638   69.975343\n",
      "8276           4      592  4.574434  692.365642  845.190798  152.825156\n",
      "8811           4       11  0.685838  713.121340  718.129766    5.008426\n",
      "9898           4      364  1.397103  752.891073  762.738833    9.847760\n",
      "10949          4      795  0.998342  788.902218  796.781586    7.879367\n",
      "10963          4      795  0.998342  788.862648  796.587706    7.725058\n",
      "12017          4      377  2.790194  824.516573  837.433395   12.916821\n",
      "      start_loc  end_loc  distance     start_t       end_t   duration\n",
      "2286          5      821  1.239477  457.041460  536.194757  79.153298\n",
      "3420          5      430  1.349425  496.000975  506.579377  10.578402\n",
      "4261          5      776  3.710905  522.806808  546.641107  23.834300\n",
      "4797          5      143  0.517507  539.704762  542.911556   3.206794\n",
      "5618          5      256  3.588919  570.412751  604.078788  33.666037\n",
      "5973          5      167  0.647687  584.279937  588.828958   4.549021\n",
      "6662          5      345  0.894282  617.918944  621.261298   3.342354\n",
      "7513          5      201  3.290270  660.040133  687.720154  27.680022\n",
      "7525          5      201  3.290270  660.232359  687.286470  27.054111\n",
      "8445          5      648  3.820739  700.891696  721.910533  21.018836\n"
     ]
    }
   ],
   "source": [
    "loc_codes = [2, 3, 4, 5]\n",
    "data_dict_0 = {}\n",
    "data_dict_1 = {}\n",
    "data_dict_2 = {}\n",
    "data_dict_3 = {}\n",
    "\n",
    "for names in bike_loc.keys():\n",
    "    data_dict_0[names] = bike_loc[names].loc[bike_loc[names]['start_loc'] == 2]\n",
    "    data_dict_1[names] = bike_loc[names].loc[bike_loc[names]['start_loc'] == 3]\n",
    "    data_dict_2[names] = bike_loc[names].loc[bike_loc[names]['start_loc'] == 4]\n",
    "    data_dict_3[names] = bike_loc[names].loc[bike_loc[names]['start_loc'] == 5]\n",
    "        \n",
    "print(list(data_dict_0.values())[0].head(10));\n",
    "print(list(data_dict_1.values())[0].head(10))\n",
    "print(list(data_dict_2.values())[0].head(10))\n",
    "print(list(data_dict_3.values())[0].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We save the departure times data at each station into a new folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('./Station2', exist_ok=True)  \n",
    "\n",
    "for names in data_dict_dep.keys():\n",
    "    data_dict_0[names].to_csv('./Station2/'+ str(names))\n",
    "\n",
    "os.makedirs('./Station3', exist_ok=True)  \n",
    "\n",
    "for names in data_dict_arr.keys():\n",
    "    data_dict_1[names].to_csv('./Station3/'+ str(names))\n",
    "\n",
    "os.makedirs('./Station4', exist_ok=True)  \n",
    "\n",
    "for names in data_dict_arr.keys():\n",
    "    data_dict_2[names].to_csv('./Station4/'+ str(names))\n",
    "                                \n",
    "os.makedirs('./Station5', exist_ok=True)  \n",
    "\n",
    "for names in data_dict_arr.keys():\n",
    "    data_dict_3[names].to_csv('./Station5/'+ str(names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then read and save departure times at all stations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc_codes = station_data['Station.Id'].to_numpy()\n",
    "\n",
    "for i in range(808):\n",
    "    \n",
    "    loc = loc_codes[i]\n",
    "    data_dict = {}\n",
    "\n",
    "    for names in bike_loc.keys():\n",
    "        data_dict[names] = bike_loc[names].loc[bike_loc[names]['start_loc'] == loc]\n",
    "    \n",
    "    path = f\"./sortdep/Station{loc}\"\n",
    "    os.makedirs(path, exist_ok=True) \n",
    "    \n",
    "    filename = f\"./sortdep/Station{loc}/{str(names)}\"\n",
    "    for names in data_dict_dep.keys():\n",
    "        filename = f\"./sortdep/Station{loc}/{str(names)}\"\n",
    "        data_dict[names].to_csv(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Add in duration.\n",
    "cols = [\"start_t\", \"end_t\",\"duration\",\"start_loc\", \"end_loc\"]\n",
    "for name in bike_data.keys():\n",
    "    bike_data[name] = bike_data[name].assign(end_t=lambda x:\n",
    "                                             abs(x.start_t + x.duration))\n",
    "    bike_data[name] = bike_data[name].reindex(columns=cols)\n",
    "\n",
    "print(list(bike_data.values())[0].head())\n",
    "\n",
    "#Map the row number to each location index in station_data.\n",
    "for name in bike_data.keys():\n",
    "    bike_data[name] = bike_data[name].to_numpy()\n",
    "    startno = np.zeros((bike_data[name].shape[0], 1), dtype=int)\n",
    "    endno = np.zeros((bike_data[name].shape[0], 1), dtype=int)\n",
    "    \n",
    "    for r in range(bike_data[name].shape[0]):\n",
    "        startno[r] = row_ID_dict[bike_data[name][r, 3]]\n",
    "        endno[r] = row_ID_dict[bike_data[name][r, 4]]\n",
    "    \n",
    "    startno = pd.DataFrame(startno)\n",
    "    endno = pd.DataFrame(endno)\n",
    "    bike_data[name] = pd.DataFrame(bike_data[name], columns = [\"start_t\", \"end_t\",\"duration\",\"start_loc\", \n",
    "                                                              \"end_loc\"])\n",
    "    \n",
    "    bike_data[name] = bike_data[name].assign(start_no = startno)\n",
    "    bike_data[name] = bike_data[name].assign(end_no = endno)\n",
    "    \n",
    "print(list(bike_data.values())[0].head())        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then we add the distance travelled for each journey."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    start_t     end_t  duration  start_loc  end_loc  distance\n",
      "0  55728000  55729500      1500         47       56  0.029266\n",
      "1  55728000  55728540       540        762      600  0.019513\n",
      "2  55728060  55728480       420        588      698  0.013609\n",
      "3  55728120  55740360     12240        456      456  0.000000\n",
      "4  55728120  55728780       660         67       67  0.000000\n",
      "5  55728120  55728420       300        243       74  0.015976\n",
      "6  55728180  55728480       300        715      444  0.011863\n",
      "7  55728180  55740420     12240        456      456  0.000000\n",
      "8  55728180  55740420     12240        456      456  0.000000\n",
      "9  55728180  55728600       420        383       83  0.003483\n"
     ]
    }
   ],
   "source": [
    "#Adding the distance column for each journey\n",
    "bike_loc = dict(bike_data)\n",
    "\n",
    "for names in bike_loc.keys():\n",
    "    bike_loc[names] = bike_loc[names].to_numpy()\n",
    "     \n",
    "    \n",
    "    dist = np.zeros((bike_loc[names].shape[0], 1), dtype = geo_dist.dtype)\n",
    "    for r in range(bike_loc[names].shape[0]):\n",
    "            dist[r] = geo_dist[bike_loc[names][r, 5], bike_loc[names][r, 6]]\n",
    "    \n",
    "    dist = pd.DataFrame(dist)\n",
    "    bike_loc[names] = pd.DataFrame(bike_loc[names], columns = [\"start_t\", \"end_t\",\"duration\",\"start_loc\", \n",
    "                                                              \"end_loc\", \"start_no\", \"end_no\"])\n",
    "    del bike_loc[names][\"start_no\"]\n",
    "    del bike_loc[names][\"end_no\"]\n",
    "    bike_loc[names] = bike_loc[names].assign(distance = dist)\n",
    "    \n",
    "print(list(bike_loc.values())[0].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we save the data into folders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc_codes = station_data['Station.Id'].to_numpy()\n",
    "\n",
    "for i in range(808):\n",
    "    \n",
    "    loc = loc_codes[i]\n",
    "    data_dict = {}\n",
    "\n",
    "    for names in bike_loc.keys():\n",
    "        data_dict[names] = bike_loc[names].loc[bike_loc[names]['start_loc'] == loc]\n",
    "    \n",
    "    path = f\"./sortarr/Station{loc}\"\n",
    "    os.makedirs(path, exist_ok=True) \n",
    "    \n",
    "    filename = f\"./sortarr/Station{loc}/{str(names)}\"\n",
    "    for names in data_dict_dep.keys():\n",
    "        filename = f\"./sortarr/Station{loc}/{str(names)}\"\n",
    "        data_dict[names].to_csv(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
